{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Mar 29 2022 22:56:14\n"
     ]
    }
   ],
   "source": [
    "from safe_control_gym.envs.manipulators.manipulator import BaseManipulator\n",
    "import numpy as np \n",
    "import random \n",
    "from time import sleep\n",
    "from safe_control_gym.envs.benchmark_env import Cost, Task\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO, DDPG, A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=\n",
      "Version = 4.1 Metal - 76.3\n",
      "Vendor = Apple\n",
      "Renderer = Apple M1 Pro\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    }
   ],
   "source": [
    "urdf_path = \"../safe_control_gym/envs/manipulators/assets/franka_panda/panda.urdf\"\n",
    "control_mode = \"torque\"\n",
    "target_space = \"joint\"\n",
    "\n",
    "controlled_joint_indices = [6]\n",
    "observed_link_indices = [7]\n",
    "observed_link_state_keys = [\"position\"]\n",
    "goal = [{\n",
    "    \"position\": [None for i in range(13)]\n",
    "}]\n",
    "\n",
    "# orientation_goal = [0.603, 0.3687, -0.3697, 0.6026]\n",
    "# position_goal = [0.03692, 0, 0.973]\n",
    "position_goal = [-0.127, 0.0, 1.012]\n",
    "# position_goal = [0.0, 0, 1]\n",
    "goal[0][\"position\"][observed_link_indices[0]] = position_goal\n",
    "goal_type = \"point\"\n",
    "\n",
    "env = BaseManipulator(\n",
    "    urdf_path,\n",
    "    control_mode,\n",
    "    target_space,\n",
    "    controlled_joint_indices = controlled_joint_indices,\n",
    "    observed_link_indices = observed_link_indices, \n",
    "    observed_link_state_keys = observed_link_state_keys,\n",
    "    goal = goal,\n",
    "    goal_type = goal_type,\n",
    "    cost = Cost.RL_REWARD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "obs: (0.08799999952316284, 3.329974913434536e-13, 1.0329999923706055)\n",
      "reward: -111.07999189410134\n",
      "[-3]\n",
      "obs: (0.08800004422664642, -1.245352763135088e-07, 1.0329999923706055)\n",
      "reward: -111.08016113252822\n",
      "[-3]\n",
      "obs: (0.087978295981884, -3.838818827262003e-07, 1.031003713607788)\n",
      "reward: -109.06239347155483\n",
      "[3]\n",
      "obs: (0.08779814839363098, -6.511243100248976e-07, 1.027016043663025)\n",
      "reward: -104.89484318096592\n",
      "[2]\n",
      "obs: (0.08779588341712952, -9.233827569232744e-08, 1.027016043663025)\n",
      "reward: -104.89201941843012\n",
      "[3]\n",
      "obs: (0.08779597282409668, -2.149775042425972e-07, 1.027016043663025)\n",
      "reward: -104.89223146462584\n",
      "[-3]\n",
      "obs: (0.08790911734104156, -6.468247448765396e-08, 1.029009222984314)\n",
      "reward: -106.99840500783003\n",
      "[-3]\n",
      "obs: (0.08790996670722961, -3.282507350377273e-07, 1.029008150100708)\n",
      "reward: -106.99844505867267\n",
      "[2]\n",
      "obs: (0.08779759705066681, -5.850599222867459e-07, 1.0270140171051025)\n",
      "reward: -104.89219921569165\n",
      "[4]\n",
      "obs: (0.08779644221067429, -3.037956730622682e-07, 1.0270140171051025)\n",
      "reward: -104.8907631114499\n",
      "[-4]\n",
      "obs: (0.08776456117630005, -1.5281118237453484e-07, 1.0324145555496216)\n",
      "reward: -110.25926953710402\n",
      "[2]\n",
      "obs: (0.08776748925447464, -7.05175864368357e-07, 1.0324124097824097)\n",
      "reward: -110.26060421274869\n",
      "[2]\n",
      "obs: (0.08776779472827911, -8.161418350027816e-07, 1.0324124097824097)\n",
      "reward: -110.2610206525238\n",
      "[3]\n",
      "obs: (0.0877680778503418, -9.168143151327968e-07, 1.0324124097824097)\n",
      "reward: -110.26140444706661\n",
      "[3]\n",
      "obs: (0.08775785565376282, -6.548821147589479e-07, 1.0344089269638062)\n",
      "reward: -112.24743749968374\n",
      "[-3]\n",
      "obs: (0.08760341256856918, -5.290866624818591e-07, 1.0383975505828857)\n",
      "reward: -116.08149223811742\n",
      "[-3]\n",
      "obs: (0.08760592341423035, -1.1148621297252248e-06, 1.0383974313735962)\n",
      "reward: -116.08446964995628\n",
      "[2]\n",
      "obs: (0.08770665526390076, -1.3636654330184683e-06, 1.0364038944244385)\n",
      "reward: -114.19191335377226\n",
      "[-3]\n",
      "obs: (0.08770551532506943, -1.0982403182424605e-06, 1.0364038944244385)\n",
      "reward: -114.19050798982616\n",
      "[-3]\n",
      "obs: (0.08776099979877472, -1.3467677035805536e-06, 1.0344079732894897)\n",
      "reward: -112.25031985596806\n",
      "[2]\n",
      "obs: (0.08773522078990936, -1.6071210211521247e-06, 1.0304161310195923)\n",
      "reward: -108.23295893052281\n",
      "[-4]\n",
      "obs: (0.08773290365934372, -1.0481783192517469e-06, 1.0304162502288818)\n",
      "reward: -108.23020206654482\n",
      "[-3]\n",
      "obs: (0.08756815642118454, -1.1804220321209868e-06, 1.0250493288040161)\n",
      "reward: -102.69866564723279\n",
      "[-3]\n",
      "obs: (0.08755116909742355, -7.990694939508103e-06, 1.025108814239502)\n",
      "reward: -102.74797403186503\n",
      "[4]\n",
      "obs: (0.0875442698597908, -1.348413024970796e-05, 1.0251556634902954)\n",
      "reward: -102.79341748033593\n",
      "[2]\n",
      "obs: (0.08758039772510529, -1.2988875823793933e-05, 1.0306103229522705)\n",
      "reward: -108.2837095531996\n",
      "[4]\n",
      "obs: (0.0875982716679573, -1.25645647131023e-05, 1.0346429347991943)\n",
      "reward: -112.33377103186476\n",
      "[3]\n",
      "obs: (0.0869278535246849, -1.1933788300666492e-05, 1.0439684391021729)\n",
      "reward: -120.98822641515844\n",
      "[4]\n",
      "obs: (0.08479577302932739, -1.1332333997415844e-05, 1.0550941228866577)\n",
      "reward: -129.98122824998254\n",
      "[-4]\n",
      "obs: (0.07912521064281464, -1.023478944262024e-05, 1.07071053981781)\n",
      "reward: -139.92598525006733\n",
      "[-4]\n",
      "obs: (0.08029859513044357, -9.887868145597167e-06, 1.0705835819244385)\n",
      "reward: -140.97206492302766\n",
      "[-3]\n",
      "obs: (0.08267881721258163, -1.0410343747935258e-05, 1.0657081604003906)\n",
      "reward: -138.4773879567202\n",
      "[-4]\n",
      "obs: (0.08509872108697891, -1.107265143218683e-05, 1.0588635206222534)\n",
      "reward: -134.05331436066453\n",
      "[2]\n",
      "obs: (0.08792764693498611, -1.1998133231827524e-05, 1.0466200113296509)\n",
      "reward: -124.63965639786883\n",
      "[-3]\n",
      "obs: (0.087600938975811, -1.1780109161918517e-05, 1.0466601848602295)\n",
      "reward: -124.35290394520243\n",
      "[4]\n",
      "obs: (0.08789501339197159, -1.1722753697540611e-05, 1.0446360111236572)\n",
      "reward: -122.62274726932637\n",
      "[3]\n",
      "obs: (0.0873984545469284, -1.09651646198472e-05, 1.0478781461715698)\n",
      "reward: -125.36756588311809\n",
      "[-3]\n",
      "obs: (0.08635083585977554, -1.059401074599009e-05, 1.0530463457107544)\n",
      "reward: -129.48777558127594\n",
      "[4]\n",
      "obs: (0.08635374158620834, -1.1213845937163569e-05, 1.0530462265014648)\n",
      "reward: -129.49118193361036\n",
      "[-4]\n",
      "obs: (0.08498256653547287, -1.0457218195369933e-05, 1.0581908226013184)\n",
      "reward: -133.2638463549866\n",
      "[-4]\n",
      "obs: (0.08498641848564148, -1.0992160241585225e-05, 1.0581860542297363)\n",
      "reward: -133.2634648756194\n",
      "[-2]\n",
      "obs: (0.08635799586772919, -1.1631578672677279e-05, 1.0530370473861694)\n",
      "reward: -129.4866748325713\n",
      "[4]\n",
      "obs: (0.0871783047914505, -1.1617811651376542e-05, 1.0491300821304321)\n",
      "reward: -126.40000473353402\n",
      "[-3]\n",
      "obs: (0.0869215726852417, -1.1007468856405467e-05, 1.0504403114318848)\n",
      "reward: -127.45289158598288\n",
      "[-3]\n",
      "obs: (0.08705132454633713, -1.122211051551858e-05, 1.0497902631759644)\n",
      "reward: -126.93280983281701\n",
      "[-2]\n",
      "obs: (0.08751998841762543, -1.1486645234981552e-05, 1.0471729040145874)\n",
      "reward: -124.78437907744782\n",
      "[-3]\n",
      "obs: (0.08772318810224533, -1.1349710803187918e-05, 1.0458624362945557)\n",
      "reward: -123.6769741076042\n",
      "[2]\n",
      "obs: (0.08814755082130432, -1.1629143955360632e-05, 1.0425671339035034)\n",
      "reward: -120.80631386876311\n",
      "[-3]\n",
      "obs: (0.08814585208892822, -1.1215249287488405e-05, 1.042567253112793)\n",
      "reward: -120.80432045100869\n",
      "[3]\n",
      "obs: (0.08834130316972733, -1.1470670870039612e-05, 1.040579915046692)\n",
      "reward: -119.01268888728927\n"
     ]
    }
   ],
   "source": [
    "action_space = [-4, -2, -3, 3, 2, 4]\n",
    "# action_space = [-400]\n",
    "\n",
    "for i in range(50):\n",
    "#     action_index = env.n_joints-2\n",
    "    action_index = 6\n",
    "    # action_list = np.zeros(env.n_joints)\n",
    "    action_list = [random.choice(action_space)]    \n",
    "    \n",
    "    # action_list = [200]\n",
    "    obs,reward, done,info = env.step(action_list)\n",
    "    # if i%5== 0 :\n",
    "    print(action_list)\n",
    "    print(f\"obs: {obs}\") # link position\n",
    "    print(f\"reward: {reward}\")\n",
    "  #   print(f\"angular velocity: {obs}\") # velocity\n",
    "                \n",
    "    sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08799999952316284, 3.329974913434536e-13, 1.0329999923706055)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring link states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_states =  env._pb_client.getLinkState(env.robot,\n",
    "                                            linkIndex=7,\n",
    "                                            computeLinkVelocity=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.088, -4.504557837847756e-13, 0.953),\n",
       " (1.0, 0.0, 0.0, 4.896583138958022e-12),\n",
       " (0.0, 0.0, 0.08),\n",
       " (0.0, 0.0, 0.0, 1.0),\n",
       " (0.08799999952316284, 3.329974913434536e-13, 1.0329999923706055),\n",
       " (1.0, 0.0, 0.0, 4.896583138958022e-12),\n",
       " (0.0, -0.0, 0.0),\n",
       " (0.0, -0.0, 0.0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only extract world positions\n",
    "link_states_dict = {\n",
    "    \"position\": link_states[4],\n",
    "    \"orientation\": link_states[5],\n",
    "    \"linear_vel\": link_states[6],\n",
    "    \"angular_vel\": link_states[7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position': (0.0010245442390441895,\n",
       "  -1.3434328138828278e-06,\n",
       "  1.0330008268356323),\n",
       " 'orientation': (0.6968757510185242,\n",
       "  -0.11944480240345001,\n",
       "  0.025003790855407715,\n",
       "  0.7067332863807678),\n",
       " 'linear_vel': (0.16140478353054072,\n",
       "  -0.021992152304630256,\n",
       "  -0.7820516002624263),\n",
       " 'angular_vel': (2.675834999501902, 19.791254360890452, -0.004319621550829485)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_states_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces \n",
    "# env.observation_space = spaces.Box(-np.inf, np.inf, (14,), dtype=np.float32)\n",
    "\n",
    "# orientation use quaternion so 4 dim \n",
    "\n",
    "# action_space = [spaces.Discrete(1) for i in range(env.n_joints-1)]\n",
    "# action_space.append(spaces.Box(-400, 400, shape=(1,), dtype=np.float32))\n",
    "\n",
    "# env.action_space = spaces.Tuple(\n",
    "#     action_space\n",
    "# )\n",
    "\n",
    "# dim dict\n",
    "dim_dict = {\n",
    "    \"position\":3 + 3,\n",
    "    \"orientation\" : 4+4\n",
    "}\n",
    "env.action_space = spaces.Box(-4.5, 4.5, (len(env.controlled_joint_indices),), dtype=np.float32)\n",
    "\n",
    "# TODO expand to multiple state keys \n",
    "env.observation_space = spaces.Box(-np.inf, np.inf, (dim_dict[observed_link_state_keys[0]], ), dtype=np.float32)\n",
    "\n",
    "# env.observation_space = spaces.Dict({\n",
    "#       'position': spaces.Box(-np.inf, np.inf, (env.n_joints, 3), dtype=np.float32),\n",
    "#       'orientation': spaces.Box(-np.inf, np.inf, (env.n_joints, 4), dtype=np.float32),\n",
    "#       'linear_vel': spaces.Box(-np.inf, np.inf, (env.n_joints, 3), dtype=np.float32),\n",
    "#       'angular_vel': spaces.Box(-np.inf, np.inf, (env.n_joints, 3), dtype=np.float32),\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 412      |\n",
      "|    ep_rew_mean     | -7.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 47       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.31e+03     |\n",
      "|    ep_rew_mean          | -2.87e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 47           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 86           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.363407e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | -1.07e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.81e+06     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -3.68e-05    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.54e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 754          |\n",
      "|    ep_rew_mean          | -1.66e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013826322 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 3.74e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.47e+06     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.25e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 754           |\n",
      "|    ep_rew_mean          | -1.66e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 46            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 177           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00066590135 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.5e+06       |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000626     |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 1.45e+07      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 754           |\n",
      "|    ep_rew_mean          | -1.66e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 48            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 210           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00074321916 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 1.04e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.1e+06       |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000681     |\n",
      "|    std                  | 0.992         |\n",
      "|    value_loss           | 6.57e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 259       |\n",
      "|    ep_rew_mean     | -4.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 35        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 58        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 259         |\n",
      "|    ep_rew_mean          | -4.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000983326 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 3.46e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.31e+06    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00074    |\n",
      "|    std                  | 0.982       |\n",
      "|    value_loss           | 9.25e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 259          |\n",
      "|    ep_rew_mean          | -4.85e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 49           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006187075 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 2.98e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.87e+06     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000361    |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 4.79e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 259          |\n",
      "|    ep_rew_mean          | -4.85e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028470703 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 1.13e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+06     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.987        |\n",
      "|    value_loss           | 7.82e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 259         |\n",
      "|    ep_rew_mean          | -4.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 53          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 190         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002463764 |\n",
      "|    clip_fraction        | 0.000928    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 1.43e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.8e+06     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 9.73e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 215       |\n",
      "|    ep_rew_mean     | -4.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 27        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 75        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 215          |\n",
      "|    ep_rew_mean          | -4.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 38           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 106          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019649784 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 5.96e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.54e+06     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00149     |\n",
      "|    std                  | 0.986        |\n",
      "|    value_loss           | 1.08e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 215         |\n",
      "|    ep_rew_mean          | -4.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 44          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004436338 |\n",
      "|    clip_fraction        | 0.00913     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 7.15e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+06     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 2.6e+06     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 215          |\n",
      "|    ep_rew_mean          | -4.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 167          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.408728e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 4.17e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.06e+06     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -3.64e-05    |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 5.66e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 215          |\n",
      "|    ep_rew_mean          | -4.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 199          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.226031e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 4.77e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.93e+06     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000156    |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 1.53e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 301       |\n",
      "|    ep_rew_mean     | -6.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 38        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 53        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 647          |\n",
      "|    ep_rew_mean          | -8.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026802826 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.41e+06     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    std                  | 0.993        |\n",
      "|    value_loss           | 1.15e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 647           |\n",
      "|    ep_rew_mean          | -8.97e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 50            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 122           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043421125 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.41         |\n",
      "|    explained_variance   | 4.17e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.17e+06      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.00012      |\n",
      "|    std                  | 0.998         |\n",
      "|    value_loss           | 2.15e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 647          |\n",
      "|    ep_rew_mean          | -8.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043928516 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+06     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 3.09e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 647          |\n",
      "|    ep_rew_mean          | -8.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004939793 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.2e+06      |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.000385    |\n",
      "|    std                  | 0.997        |\n",
      "|    value_loss           | 6.1e+06      |\n",
      "------------------------------------------\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 58   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 35   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006162005 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.47e+06     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.000385    |\n",
      "|    std                  | 0.99         |\n",
      "|    value_loss           | 5.91e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 61           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 99           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010810352 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.87e+06     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.981        |\n",
      "|    value_loss           | 7.32e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050232206 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 4.17e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.61e+06     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 5.22e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 62           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 163          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008242511 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 1.19e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8e+06        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 1.7e+07      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 206      |\n",
      "|    ep_rew_mean     | -3.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 45       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 206          |\n",
      "|    ep_rew_mean          | -3.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 54           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 75           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011585264 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.33e+06     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.000697    |\n",
      "|    std                  | 0.978        |\n",
      "|    value_loss           | 4.15e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 206          |\n",
      "|    ep_rew_mean          | -3.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032987904 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.84e+06     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    std                  | 0.977        |\n",
      "|    value_loss           | 9.2e+06      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 206         |\n",
      "|    ep_rew_mean          | -3.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 58          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 140         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003559018 |\n",
      "|    clip_fraction        | 0.00503     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2e+06       |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00257    |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 4.11e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 206          |\n",
      "|    ep_rew_mean          | -3.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 58           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 173          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.226829e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.29e+06     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | 2.45e-05     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 8.49e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 358       |\n",
      "|    ep_rew_mean     | -7.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 39        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 51        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 358          |\n",
      "|    ep_rew_mean          | -7.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010777063 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.92e+06     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.000926    |\n",
      "|    std                  | 0.963        |\n",
      "|    value_loss           | 1.05e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 358          |\n",
      "|    ep_rew_mean          | -7.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 52           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 117          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047257524 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.42e+06     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    std                  | 0.957        |\n",
      "|    value_loss           | 4.59e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 358         |\n",
      "|    ep_rew_mean          | -7.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 54          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002952402 |\n",
      "|    clip_fraction        | 0.00308     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+06     |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    std                  | 0.961       |\n",
      "|    value_loss           | 4.77e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 358          |\n",
      "|    ep_rew_mean          | -7.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 56           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003080967 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.1e+06      |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.000255    |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 9.44e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 170       |\n",
      "|    ep_rew_mean     | -2.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 22        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 90        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 30           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 132          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.821062e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.63e+06     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -3.94e-06    |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 8.94e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 39           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 155          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012432918 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | -2.38e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.41e+06     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.000732    |\n",
      "|    std                  | 0.968        |\n",
      "|    value_loss           | 5.52e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 190          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 45           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 180          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057903975 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.39        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+06     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    std                  | 0.97         |\n",
      "|    value_loss           | 4.84e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 190           |\n",
      "|    ep_rew_mean          | -3.49e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 49            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 208           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00095963094 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.39         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.47e+06      |\n",
      "|    n_updates            | 390           |\n",
      "|    policy_gradient_loss | -0.000792     |\n",
      "|    std                  | 0.97          |\n",
      "|    value_loss           | 9.14e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 402       |\n",
      "|    ep_rew_mean     | -5.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 43        |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 46        |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 287          |\n",
      "|    ep_rew_mean          | -4.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 36           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018760199 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.62e+06     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.962        |\n",
      "|    value_loss           | 7.49e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | -4.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 40           |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034769713 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.96e+06     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 0.965        |\n",
      "|    value_loss           | 8.91e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | -4.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015976115 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.96e+06     |\n",
      "|    n_updates            | 430          |\n",
      "|    policy_gradient_loss | -0.000694    |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 3.95e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | -4.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 51           |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 197          |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037869832 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.5e+06      |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 0.964        |\n",
      "|    value_loss           | 2.91e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 207      |\n",
      "|    ep_rew_mean     | -3.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 33       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | -3.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 47          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005259896 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.39e+06    |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    std                  | 0.958       |\n",
      "|    value_loss           | 8.66e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 244         |\n",
      "|    ep_rew_mean          | -3.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 56          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004651869 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 1.19e-07    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.97e+06    |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.959       |\n",
      "|    value_loss           | 3.31e+06    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 244           |\n",
      "|    ep_rew_mean          | -3.89e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 62            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 131           |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071369414 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.38         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.53e+06      |\n",
      "|    n_updates            | 480           |\n",
      "|    policy_gradient_loss | -0.000489     |\n",
      "|    std                  | 0.958         |\n",
      "|    value_loss           | 5.36e+06      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 244           |\n",
      "|    ep_rew_mean          | -3.89e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 66            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023038004 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.38         |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.25e+07      |\n",
      "|    n_updates            | 490           |\n",
      "|    policy_gradient_loss | -0.000327     |\n",
      "|    std                  | 0.961         |\n",
      "|    value_loss           | 2.5e+07       |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ppo_model = PPO('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# use this to stop if too many timesteps cannot converge to done \n",
    "for i in range(10):\n",
    "    ppo_model.learn(total_timesteps=10000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_model.save(\"manipulator_100000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0\n",
      "action: [1.0969899]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.088, 0.0, 1.033, -0.127, 0.0, 1.012]\n",
      "reward: -235.9999918941013\n",
      "\n",
      "Iteration:5\n",
      "action: [0.79837924]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.083, 0.0, 1.062, -0.127, 0.0, 1.012]\n",
      "reward: -260.30347805373367\n",
      "\n",
      "Iteration:10\n",
      "action: [0.39074004]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.031, 0.0, 1.116, -0.127, 0.0, 1.012]\n",
      "reward: -262.0205112741496\n",
      "\n",
      "Iteration:15\n",
      "action: [-0.17638242]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.005, 0.0, 1.121, -0.127, 0.0, 1.012]\n",
      "reward: -241.0641707067407\n",
      "\n",
      "Iteration:20\n",
      "action: [-0.15105997]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.011, 0.0, 1.12, -0.127, 0.0, 1.012]\n",
      "reward: -246.31752239678463\n",
      "\n",
      "Iteration:25\n",
      "action: [-0.0033571]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.04, 0.0, 1.112, -0.127, 0.0, 1.012]\n",
      "reward: -266.9568698386138\n",
      "\n",
      "Iteration:30\n",
      "action: [1.367567]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.064, 0.0, 1.097, -0.127, 0.0, 1.012]\n",
      "reward: -276.13823216801393\n",
      "\n",
      "Iteration:35\n",
      "action: [-0.28238034]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.064, 0.0, 1.097, -0.127, 0.0, 1.012]\n",
      "reward: -276.15266442830034\n",
      "\n",
      "Iteration:40\n",
      "action: [-0.29583764]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.069, 0.0, 1.092, -0.127, 0.0, 1.012]\n",
      "reward: -276.0465651119739\n",
      "\n",
      "Iteration:45\n",
      "action: [-0.03609215]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.077, 0.0, 1.082, -0.127, 0.0, 1.012]\n",
      "reward: -273.96318713021174\n",
      "\n",
      "Iteration:50\n",
      "action: [-1.9966618]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.08, 0.0, 1.077, -0.127, 0.0, 1.012]\n",
      "reward: -272.0729044979089\n",
      "\n",
      "Iteration:55\n",
      "action: [0.07440783]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.078, 0.0, 1.081, -0.127, 0.0, 1.012]\n",
      "reward: -273.395541315258\n",
      "\n",
      "Iteration:60\n",
      "action: [2.6693285]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.058, 0.0, 1.103, -0.127, 0.0, 1.012]\n",
      "reward: -275.2626769054041\n",
      "\n",
      "Iteration:65\n",
      "action: [-1.3302017]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.035, 0.0, 1.113, -0.127, 0.0, 1.012]\n",
      "reward: -263.6903784389142\n",
      "\n",
      "Iteration:70\n",
      "action: [-2.088752]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.05, 0.0, 1.105, -0.127, 0.0, 1.012]\n",
      "reward: -269.64530527788156\n",
      "\n",
      "Iteration:75\n",
      "action: [-0.87183183]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.052, 0.0, 1.103, -0.127, 0.0, 1.012]\n",
      "reward: -270.5631329138123\n",
      "\n",
      "Iteration:80\n",
      "action: [1.2499644]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.054, 0.0, 1.102, -0.127, 0.0, 1.012]\n",
      "reward: -270.92511440991075\n",
      "\n",
      "Iteration:85\n",
      "action: [-0.7137393]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.047, 0.0, 1.107, -0.127, 0.0, 1.012]\n",
      "reward: -269.0962830076751\n",
      "\n",
      "Iteration:90\n",
      "action: [1.7131695]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.047, 0.0, 1.107, -0.127, 0.0, 1.012]\n",
      "reward: -269.0949516966066\n",
      "\n",
      "Iteration:95\n",
      "action: [-0.4705372]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.028, 0.0, 1.116, -0.127, 0.0, 1.012]\n",
      "reward: -259.0701773517503\n",
      "\n",
      "Iteration:100\n",
      "action: [0.33396834]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.045, 0.0, 1.107, -0.127, 0.0, 1.012]\n",
      "reward: -267.83589057617064\n",
      "\n",
      "Iteration:105\n",
      "action: [0.38907555]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.039, 0.0, 1.111, -0.127, 0.0, 1.012]\n",
      "reward: -265.40845538896974\n",
      "\n",
      "Iteration:110\n",
      "action: [1.151711]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.041, 0.0, 1.11, -0.127, 0.0, 1.012]\n",
      "reward: -266.21671972519835\n",
      "\n",
      "Iteration:115\n",
      "action: [0.9617622]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.041, 0.0, 1.11, -0.127, 0.0, 1.012]\n",
      "reward: -266.21636665571714\n",
      "\n",
      "Iteration:120\n",
      "action: [-0.8933946]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.034, 0.0, 1.114, -0.127, 0.0, 1.012]\n",
      "reward: -262.5890207984776\n",
      "\n",
      "Iteration:125\n",
      "action: [-0.71153945]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.034, 0.0, 1.114, -0.127, 0.0, 1.012]\n",
      "reward: -262.63486107767676\n",
      "\n",
      "Iteration:130\n",
      "action: [1.2690598]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [0.015, 0.0, 1.119, -0.127, 0.0, 1.012]\n",
      "reward: -249.50405065486848\n",
      "\n",
      "Iteration:135\n",
      "action: [0.46145517]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.017, -0.0, 1.12, -0.127, 0.0, 1.012]\n",
      "reward: -218.56605553170084\n",
      "\n",
      "Iteration:140\n",
      "action: [-1.4578583]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.032, -0.0, 1.118, -0.127, 0.0, 1.012]\n",
      "reward: -200.80347191127657\n",
      "\n",
      "Iteration:145\n",
      "action: [-0.6288447]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.045, -0.0, 1.114, -0.127, 0.0, 1.012]\n",
      "reward: -183.47280850161042\n",
      "\n",
      "Iteration:150\n",
      "action: [0.37723404]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.04, -0.0, 1.116, -0.127, 0.0, 1.012]\n",
      "reward: -191.8319160270039\n",
      "\n",
      "Iteration:155\n",
      "action: [-0.7683815]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.053, -0.0, 1.108, -0.127, 0.0, 1.012]\n",
      "reward: -170.75658748966816\n",
      "\n",
      "Iteration:160\n",
      "action: [0.15267548]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.07, -0.0, 1.099, -0.127, 0.0, 1.012]\n",
      "reward: -144.09505897150666\n",
      "\n",
      "Iteration:165\n",
      "action: [1.220984]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.09, -0.0, 1.068, -0.127, 0.0, 1.012]\n",
      "reward: -93.15221978999033\n",
      "\n",
      "Iteration:170\n",
      "action: [0.6786096]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.109, -0.0, 1.044, -0.127, 0.0, 1.012]\n",
      "reward: -49.78098006016807\n",
      "\n",
      "Iteration:175\n",
      "action: [-0.53011477]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.114, -0.0, 1.039, -0.127, 0.0, 1.012]\n",
      "reward: -39.87210510262229\n",
      "\n",
      "Iteration:180\n",
      "action: [0.42264235]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.112, -0.0, 1.057, -0.127, 0.0, 1.012]\n",
      "reward: -60.88994227888178\n",
      "\n",
      "Iteration:185\n",
      "action: [1.3865964]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.107, -0.0, 1.06, -0.127, 0.0, 1.012]\n",
      "reward: -68.18480685818939\n",
      "\n",
      "Iteration:190\n",
      "action: [0.73384035]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.112, -0.0, 1.045, -0.127, 0.0, 1.012]\n",
      "reward: -48.58133491346961\n",
      "\n",
      "Iteration:195\n",
      "action: [2.4651418]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.114, -0.0, 1.028, -0.127, 0.0, 1.012]\n",
      "reward: -29.34461325297888\n",
      "\n",
      "Iteration:200\n",
      "action: [-0.35992238]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.112, -0.0, 0.999, -0.127, 0.0, 1.012]\n",
      "reward: -27.36433430515173\n",
      "\n",
      "Iteration:205\n",
      "action: [0.7619165]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.103, -0.0, 0.98, -0.127, 0.0, 1.012]\n",
      "reward: -55.684834221086945\n",
      "\n",
      "Iteration:210\n",
      "action: [0.38761893]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.101, -0.0, 0.972, -0.127, 0.0, 1.012]\n",
      "reward: -65.88932565670258\n",
      "\n",
      "Iteration:215\n",
      "action: [-0.93493617]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.101, -0.0, 0.973, -0.127, 0.0, 1.012]\n",
      "reward: -65.49560830977863\n",
      "\n",
      "Iteration:220\n",
      "action: [0.04037058]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.1, -0.0, 0.973, -0.127, 0.0, 1.012]\n",
      "reward: -65.4263228615164\n",
      "\n",
      "Iteration:225\n",
      "action: [0.9238069]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.102, -0.0, 0.975, -0.127, 0.0, 1.012]\n",
      "reward: -62.54904783132953\n",
      "\n",
      "Iteration:230\n",
      "action: [-0.9644269]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.102, -0.0, 0.975, -0.127, 0.0, 1.012]\n",
      "reward: -62.51920646615328\n",
      "\n",
      "Iteration:235\n",
      "action: [-1.0432981]\n",
      "goal: [-0.127, 0.0, 1.012]\n",
      "state: [-0.111, -0.0, 0.989, -0.127, 0.0, 1.012]\n",
      "reward: -39.66943038254978\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for i in range(500):\n",
    "    action, _state = ppo_model.predict(obs, deterministic=False)\n",
    "    # print(_state)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    applied_action = env._action_mapping_torque(action)\n",
    "    \n",
    "    if i%5==0:\n",
    "        print(f\"Iteration:{i}\")\n",
    "        print(f\"action: {action}\")\n",
    "        print(f\"goal: {goal[0]['position'][7]}\")\n",
    "        print(f\"state: {[round(ob,3) for ob in obs]}\")\n",
    "        print(f\"reward: {reward}\\n\")\n",
    "    \n",
    "    if done: \n",
    "        print(\"done\")\n",
    "        break\n",
    "    \n",
    "    sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8621da41d1f75996b3114ed85820b1f2b9a1702c3804dac4519b835c2698d1e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('sc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
