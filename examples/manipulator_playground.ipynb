{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Mar 29 2022 22:56:14\n"
     ]
    }
   ],
   "source": [
    "from safe_control_gym.envs.manipulators.manipulator import BaseManipulator\n",
    "import numpy as np \n",
    "import random \n",
    "from time import sleep\n",
    "from safe_control_gym.envs.benchmark_env import Cost, Task\n",
    "from gym import spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=\n",
      "Version = 4.1 Metal - 76.3\n",
      "Vendor = Apple\n",
      "Renderer = Apple M1 Pro\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    }
   ],
   "source": [
    "urdf_path = \"../safe_control_gym/envs/manipulators/assets/franka_panda/panda.urdf\"\n",
    "control_mode = \"torque\"\n",
    "target_space = \"joint\"\n",
    "\n",
    "controlled_joint_indices = [6]\n",
    "observed_link_indices = [6]\n",
    "observed_link_state_keys = [\"orientation\"]\n",
    "goal = [{\n",
    "    \"orientation\": [None for i in range(13)]\n",
    "}]\n",
    "\n",
    "orientation_goal = [0.603, 0.3687, -0.3697, 0.6026] \n",
    "goal[0][\"orientation\"][observed_link_indices[0]] = orientation_goal\n",
    "goal_type = \"point\"\n",
    "\n",
    "env = BaseManipulator(\n",
    "    urdf_path,\n",
    "    control_mode,\n",
    "    target_space,\n",
    "    controlled_joint_indices = controlled_joint_indices,\n",
    "    observed_link_indices = observed_link_indices, \n",
    "    observed_link_state_keys = observed_link_state_keys,\n",
    "    goal = goal,\n",
    "    goal_type = goal_type,\n",
    "    cost = Cost.RL_REWARD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position': [[], [], [], [], [], [], [], [], [], [], [], [], []],\n",
       " 'orientation': [[], [], [], [], [], [], [], [], [], [], [], [], []],\n",
       " 'linear_vel': [[], [], [], [], [], [], [], [], [], [], [], [], []],\n",
       " 'angular_vel': [[], [], [], [], [], [], [], [], [], [], [], [], []]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.link_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n",
      "obs: (0.7071067690849304, 0.0, 0.0, 0.7071067690849304)\n",
      "reward: -0.9470135381698608\n"
     ]
    }
   ],
   "source": [
    "# action_space = [ -200, -300, -400, 200, 300, 400,]\n",
    "action_space = [0]\n",
    "\n",
    "for i in range(50):\n",
    "#     action_index = env.n_joints-2\n",
    "    action_index = 6\n",
    "    action_list = np.zeros(env.n_joints)\n",
    "    action_list[action_index] = random.choice(action_space)    \n",
    "    obs,reward, done,info = env.step(action_list)\n",
    "    if i%5== 0 :\n",
    "          print(f\"obs: {obs}\") # link position\n",
    "          print(f\"reward: {reward}\")\n",
    "        #   print(f\"angular velocity: {obs}\") # velocity\n",
    "                \n",
    "    sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.n_joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_states =  env._pb_client.getLinkState(env.robot,\n",
    "                                            linkIndex=6,\n",
    "                                            computeLinkVelocity=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.039833163452802724, -0.005246717093960421, 1.0411480839438747),\n",
       " (0.6968757615251299,\n",
       "  -0.11944479553082608,\n",
       "  0.025003790002564637,\n",
       "  0.7067332766361558),\n",
       " (0.04, 0.0, 0.0),\n",
       " (0.0, 0.0, 0.0, 1.0),\n",
       " (0.0010245442390441895, -1.3434328138828278e-06, 1.0330008268356323),\n",
       " (0.6968757510185242,\n",
       "  -0.11944480240345001,\n",
       "  0.025003790855407715,\n",
       "  0.7067332863807678),\n",
       " (0.16140478353054072, -0.021992152304630256, -0.7820516002624263),\n",
       " (2.675834999501902, 19.791254360890452, -0.004319621550829485))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only extract world positions\n",
    "link_states_dict = {\n",
    "    \"position\": link_states[4],\n",
    "    \"orientation\": link_states[5],\n",
    "    \"linear_vel\": link_states[6],\n",
    "    \"angular_vel\": link_states[7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'position': (0.0010245442390441895,\n",
       "  -1.3434328138828278e-06,\n",
       "  1.0330008268356323),\n",
       " 'orientation': (0.6968757510185242,\n",
       "  -0.11944480240345001,\n",
       "  0.025003790855407715,\n",
       "  0.7067332863807678),\n",
       " 'linear_vel': (0.16140478353054072,\n",
       "  -0.021992152304630256,\n",
       "  -0.7820516002624263),\n",
       " 'angular_vel': (2.675834999501902, 19.791254360890452, -0.004319621550829485)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link_states_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.link_states[\"position\"][1] = [4,3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# point \n",
    "# 1.0330\n",
    "\n",
    "# orientation:\n",
    "# (0.6034725904464722, 0.3687118589878082, -0.3697621822357178, 0.6026179194450378)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces \n",
    "# env.observation_space = spaces.Box(-np.inf, np.inf, (14,), dtype=np.float32)\n",
    "\n",
    "# orientation use quaternion so 4 dim \n",
    "\n",
    "# action_space = [spaces.Discrete(1) for i in range(env.n_joints-1)]\n",
    "# action_space.append(spaces.Box(-400, 400, shape=(1,), dtype=np.float32))\n",
    "\n",
    "# env.action_space = spaces.Tuple(\n",
    "#     action_space\n",
    "# )\n",
    "\n",
    "# dim dict\n",
    "dim_dict = {\n",
    "    \"orientation\" : 4 \n",
    "}\n",
    "env.action_space = spaces.Box(-300, -200, (env.n_joints,), dtype=np.float32)\n",
    "\n",
    "# TODO expand to multiple state keys \n",
    "env.observation_space = spaces.Box(-np.inf, np.inf, (dim_dict[observed_link_state_keys[0]], ), dtype=np.float32)\n",
    "\n",
    "# env.observation_space = spaces.Dict({\n",
    "#       'position': spaces.Box(-np.inf, np.inf, (env.n_joints, 3), dtype=np.float32),\n",
    "#       'orientation': spaces.Box(-np.inf, np.inf, (env.n_joints, 4), dtype=np.float32),\n",
    "#       'linear_vel': spaces.Box(-np.inf, np.inf, (env.n_joints, 3), dtype=np.float32),\n",
    "#       'angular_vel': spaces.Box(-np.inf, np.inf, (env.n_joints, 3), dtype=np.float32),\n",
    "#     })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -18.6    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -213     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 148      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 55       |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -18.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -182     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 139      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.a2c.a2c.A2C at 0x7fb0a2293190>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "import gym \n",
    "# model = PPO('MultiInputPolicy', env, verbose=1)\n",
    "# model.learn(total_timesteps=10)\n",
    "# env = gym.make('CartPole-v1')\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.27052879333496094, -0.6532025933265686, 0.6544196605682373, -0.2680959105491638)\n",
      "reward: -3.7902469577789306\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.27053022384643555, -0.6532018780708313, 0.6544206142425537, -0.26809409260749817)\n",
      "reward: -3.7902468087673187\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.27053162455558777, -0.6532010436058044, 0.6544215679168701, -0.26809221506118774)\n",
      "reward: -3.79024645113945\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.2705330550670624, -0.6532003283500671, 0.6544225215911865, -0.2680903971195221)\n",
      "reward: -3.790246302127838\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.270534485578537, -0.6531995534896851, 0.6544234156608582, -0.26808851957321167)\n",
      "reward: -3.790245974302292\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.2705358862876892, -0.6531988382339478, 0.6544243097305298, -0.268086701631546)\n",
      "reward: -3.7902457358837127\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.2705373466014862, -0.6531981229782104, 0.6544252634048462, -0.268084853887558)\n",
      "reward: -3.790245586872101\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.27053871750831604, -0.6531972885131836, 0.6544261574745178, -0.26808297634124756)\n",
      "reward: -3.790245139837265\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.27054011821746826, -0.6531965136528015, 0.6544271111488342, -0.2680811285972595)\n",
      "reward: -3.7902448716163635\n",
      "action: [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200. -200.\n",
      " -200.]\n",
      "goal: [0.603, 0.3687, -0.3697, 0.6026]\n",
      "state: (-0.27054154872894287, -0.6531957983970642, 0.6544280052185059, -0.2680792808532715)\n",
      "reward: -3.7902446331977844\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "for i in range(10):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    print(f\"action: {action}\")\n",
    "    print(f\"goal: {goal[0]['orientation'][6]}\")\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"state: {obs}\")\n",
    "    print(f\"reward: {reward}\")\n",
    "    sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing observation_space and action_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces \n",
    "_action_space = spaces.Box(0, 2, (2,2), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([[0. 0.]\n",
       " [0. 0.]], [[2. 2.]\n",
       " [2. 2.]], (2, 2), float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8621da41d1f75996b3114ed85820b1f2b9a1702c3804dac4519b835c2698d1e6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('sc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
